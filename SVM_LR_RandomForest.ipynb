{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee4d4d5",
   "metadata": {},
   "source": [
    "# SVM, LR and Random Forest\n",
    "\n",
    "Siew Wei Feng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8700a",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d8c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#to reaccess\n",
    "f = open('x_train.pckl', 'rb')\n",
    "x_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('x_test.pckl', 'rb')\n",
    "x_test = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('y_train.pckl', 'rb')\n",
    "y_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('y_test.pckl', 'rb')\n",
    "y_test = pickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d776cabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.139053</td>\n",
       "      <td>0.085954</td>\n",
       "      <td>0.134424</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.019548</td>\n",
       "      <td>0.039812</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.047265</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349064</td>\n",
       "      <td>0.107314</td>\n",
       "      <td>-0.197132</td>\n",
       "      <td>0.109178</td>\n",
       "      <td>0.292737</td>\n",
       "      <td>0.191383</td>\n",
       "      <td>0.073168</td>\n",
       "      <td>0.016185</td>\n",
       "      <td>0.120109</td>\n",
       "      <td>-0.019581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.155482</td>\n",
       "      <td>0.092528</td>\n",
       "      <td>0.087958</td>\n",
       "      <td>-0.006443</td>\n",
       "      <td>0.032637</td>\n",
       "      <td>0.091513</td>\n",
       "      <td>-0.024549</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.040707</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328685</td>\n",
       "      <td>0.113341</td>\n",
       "      <td>-0.047412</td>\n",
       "      <td>-0.083207</td>\n",
       "      <td>0.077209</td>\n",
       "      <td>0.150267</td>\n",
       "      <td>0.034841</td>\n",
       "      <td>-0.167317</td>\n",
       "      <td>0.075683</td>\n",
       "      <td>0.011139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.147152</td>\n",
       "      <td>0.135515</td>\n",
       "      <td>0.160577</td>\n",
       "      <td>-0.011785</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.032933</td>\n",
       "      <td>-0.039414</td>\n",
       "      <td>0.091675</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443020</td>\n",
       "      <td>0.318361</td>\n",
       "      <td>0.036487</td>\n",
       "      <td>0.141171</td>\n",
       "      <td>0.242982</td>\n",
       "      <td>0.058814</td>\n",
       "      <td>-0.170503</td>\n",
       "      <td>0.040575</td>\n",
       "      <td>-0.080709</td>\n",
       "      <td>-0.162065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.151337</td>\n",
       "      <td>0.025105</td>\n",
       "      <td>0.133567</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>-0.009014</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>-0.076242</td>\n",
       "      <td>0.088142</td>\n",
       "      <td>-0.022388</td>\n",
       "      <td>-0.060334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385004</td>\n",
       "      <td>-0.086752</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>0.035045</td>\n",
       "      <td>-0.017515</td>\n",
       "      <td>0.114395</td>\n",
       "      <td>-0.237837</td>\n",
       "      <td>0.083261</td>\n",
       "      <td>0.048203</td>\n",
       "      <td>0.010538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.145445</td>\n",
       "      <td>0.109250</td>\n",
       "      <td>0.171711</td>\n",
       "      <td>0.040833</td>\n",
       "      <td>-0.017474</td>\n",
       "      <td>-0.001341</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.105575</td>\n",
       "      <td>0.028514</td>\n",
       "      <td>-0.056779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384351</td>\n",
       "      <td>0.089327</td>\n",
       "      <td>-0.154313</td>\n",
       "      <td>0.092013</td>\n",
       "      <td>0.032642</td>\n",
       "      <td>0.073208</td>\n",
       "      <td>0.131769</td>\n",
       "      <td>0.129483</td>\n",
       "      <td>0.101375</td>\n",
       "      <td>0.053342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>-0.161575</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.151651</td>\n",
       "      <td>-0.039999</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>0.084016</td>\n",
       "      <td>-0.018009</td>\n",
       "      <td>0.060704</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>-0.040601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310920</td>\n",
       "      <td>0.087655</td>\n",
       "      <td>-0.079134</td>\n",
       "      <td>0.030907</td>\n",
       "      <td>0.132617</td>\n",
       "      <td>0.114127</td>\n",
       "      <td>0.015371</td>\n",
       "      <td>-0.037972</td>\n",
       "      <td>0.098409</td>\n",
       "      <td>-0.032257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>-0.089031</td>\n",
       "      <td>0.156806</td>\n",
       "      <td>0.168515</td>\n",
       "      <td>0.054757</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>-0.005096</td>\n",
       "      <td>-0.012236</td>\n",
       "      <td>0.101809</td>\n",
       "      <td>-0.019814</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432577</td>\n",
       "      <td>0.264423</td>\n",
       "      <td>0.253214</td>\n",
       "      <td>-0.064371</td>\n",
       "      <td>0.176547</td>\n",
       "      <td>0.154475</td>\n",
       "      <td>-0.207800</td>\n",
       "      <td>-0.040884</td>\n",
       "      <td>0.112471</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>-0.141774</td>\n",
       "      <td>0.106623</td>\n",
       "      <td>0.119957</td>\n",
       "      <td>0.017220</td>\n",
       "      <td>0.031261</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>-0.023757</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>-0.016680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151211</td>\n",
       "      <td>0.072479</td>\n",
       "      <td>-0.107399</td>\n",
       "      <td>-0.055039</td>\n",
       "      <td>0.132766</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>-0.031553</td>\n",
       "      <td>-0.185985</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>0.081448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>-0.081258</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>0.136440</td>\n",
       "      <td>0.056546</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>-0.010508</td>\n",
       "      <td>-0.038380</td>\n",
       "      <td>-0.004174</td>\n",
       "      <td>-0.036269</td>\n",
       "      <td>0.052961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339121</td>\n",
       "      <td>0.150784</td>\n",
       "      <td>-0.219521</td>\n",
       "      <td>0.030969</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>0.127398</td>\n",
       "      <td>-0.092799</td>\n",
       "      <td>0.062099</td>\n",
       "      <td>-0.062101</td>\n",
       "      <td>-0.069058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>-0.144677</td>\n",
       "      <td>0.068084</td>\n",
       "      <td>0.180762</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.026864</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.131573</td>\n",
       "      <td>-0.032199</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472130</td>\n",
       "      <td>0.257942</td>\n",
       "      <td>0.049884</td>\n",
       "      <td>0.203072</td>\n",
       "      <td>0.053388</td>\n",
       "      <td>0.156444</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>0.208271</td>\n",
       "      <td>-0.357767</td>\n",
       "      <td>-0.090734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -0.139053  0.085954  0.134424  0.007430  0.019548  0.039812  0.024023   \n",
       "1     -0.155482  0.092528  0.087958 -0.006443  0.032637  0.091513 -0.024549   \n",
       "2     -0.147152  0.135515  0.160577 -0.011785  0.035533  0.032933 -0.039414   \n",
       "3     -0.151337  0.025105  0.133567  0.029539 -0.009014  0.011786 -0.076242   \n",
       "4     -0.145445  0.109250  0.171711  0.040833 -0.017474 -0.001341  0.001930   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11995 -0.161575  0.003154  0.151651 -0.039999  0.029624  0.084016 -0.018009   \n",
       "11996 -0.089031  0.156806  0.168515  0.054757  0.014283 -0.005096 -0.012236   \n",
       "11997 -0.141774  0.106623  0.119957  0.017220  0.031261  0.023168 -0.023757   \n",
       "11998 -0.081258  0.037862  0.136440  0.056546  0.019306 -0.010508 -0.038380   \n",
       "11999 -0.144677  0.068084  0.180762  0.027812  0.026864  0.010404  0.015849   \n",
       "\n",
       "            7         8         9    ...       190       191       192  \\\n",
       "0      0.047265  0.009495  0.017839  ...  0.349064  0.107314 -0.197132   \n",
       "1      0.001986  0.040707  0.020159  ...  0.328685  0.113341 -0.047412   \n",
       "2      0.091675  0.009731  0.005287  ...  0.443020  0.318361  0.036487   \n",
       "3      0.088142 -0.022388 -0.060334  ...  0.385004 -0.086752  0.113248   \n",
       "4      0.105575  0.028514 -0.056779  ...  0.384351  0.089327 -0.154313   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "11995  0.060704  0.002283 -0.040601  ...  0.310920  0.087655 -0.079134   \n",
       "11996  0.101809 -0.019814  0.000736  ...  0.432577  0.264423  0.253214   \n",
       "11997  0.079469  0.008146 -0.016680  ...  0.151211  0.072479 -0.107399   \n",
       "11998 -0.004174 -0.036269  0.052961  ...  0.339121  0.150784 -0.219521   \n",
       "11999  0.131573 -0.032199  0.002230  ...  0.472130  0.257942  0.049884   \n",
       "\n",
       "            193       194       195       196       197       198       199  \n",
       "0      0.109178  0.292737  0.191383  0.073168  0.016185  0.120109 -0.019581  \n",
       "1     -0.083207  0.077209  0.150267  0.034841 -0.167317  0.075683  0.011139  \n",
       "2      0.141171  0.242982  0.058814 -0.170503  0.040575 -0.080709 -0.162065  \n",
       "3      0.035045 -0.017515  0.114395 -0.237837  0.083261  0.048203  0.010538  \n",
       "4      0.092013  0.032642  0.073208  0.131769  0.129483  0.101375  0.053342  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "11995  0.030907  0.132617  0.114127  0.015371 -0.037972  0.098409 -0.032257  \n",
       "11996 -0.064371  0.176547  0.154475 -0.207800 -0.040884  0.112471  0.043367  \n",
       "11997 -0.055039  0.132766  0.046557 -0.031553 -0.185985  0.186369  0.081448  \n",
       "11998  0.030969  0.006442  0.127398 -0.092799  0.062099 -0.062101 -0.069058  \n",
       "11999  0.203072  0.053388  0.156444 -0.038239  0.208271 -0.357767 -0.090734  \n",
       "\n",
       "[12000 rows x 200 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91694a27",
   "metadata": {},
   "source": [
    "### Rescale and reformat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b05b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.concat([x_train, x_test])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a5318c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#rescale values in each column to between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "max = scaler.data_max_ # get max values in each column\n",
    "x= scaler.transform(x)\n",
    "x= pd.DataFrame(x)\n",
    "x = pd.DataFrame.to_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980a610b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91159ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to desired format\n",
    "y = (pd.DataFrame.to_numpy(y)).reshape((len(y),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b8e1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b7ef2",
   "metadata": {},
   "source": [
    "### Model training and evaluation (5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18789661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from statistics import mean\n",
    "\n",
    "def k_fold_cross_validation_scores(clf,x,y,k):\n",
    "\n",
    "    kf = KFold(n_splits =k, shuffle= True, random_state= 21)\n",
    "\n",
    "    Tot_acc=[]\n",
    "    Tot_pre=[]\n",
    "    Tot_rec=[]\n",
    "    Tot_f1=[]\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for train, test in kf.split(x):\n",
    "\n",
    "        i=i+1\n",
    "        print(\"\\nFold %d\" %(i))\n",
    "        \n",
    "        x_train, x_test = x[train],  x[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        y_pred = clf.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "        acc=accuracy_score(y_test, y_pred)\n",
    "        pre=precision_score(y_test, y_pred)\n",
    "        rec=recall_score(y_test, y_pred)\n",
    "        f1=f1_score(y_test, y_pred)\n",
    "        \n",
    "        Tot_acc.append(acc)\n",
    "        Tot_pre.append(pre)\n",
    "        Tot_rec.append(rec)\n",
    "        Tot_f1.append(f1)\n",
    "\n",
    "    print (\"\\nAverage Accuracy: %2.3f\" % (mean(Tot_acc)))\n",
    "    print (\"\\nAverage Precision: %2.3f\" % (mean(Tot_pre)))\n",
    "    print (\"\\nAverage Recall: %2.3f\" % (mean(Tot_rec)))\n",
    "    print (\"\\nAverage F1-score: %2.3f\" % (mean(Tot_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d56af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1942b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "\n",
      "Fold 2\n",
      "\n",
      "Fold 3\n",
      "\n",
      "Fold 4\n",
      "\n",
      "Fold 5\n",
      "\n",
      "Average Accuracy: 0.570\n",
      "\n",
      "Average Precision: 0.562\n",
      "\n",
      "Average Recall: 0.637\n",
      "\n",
      "Average F1-score: 0.596\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "k_fold_cross_validation_scores(clf= svm,x=x,y= y,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b374b703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "\n",
      "Fold 2\n",
      "\n",
      "Fold 3\n",
      "\n",
      "Fold 4\n",
      "\n",
      "Fold 5\n",
      "\n",
      "Average Accuracy: 0.479\n",
      "\n",
      "Average Precision: 0.480\n",
      "\n",
      "Average Recall: 0.490\n",
      "\n",
      "Average F1-score: 0.484\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1, solver='liblinear', random_state=42)\n",
    "k_fold_cross_validation_scores(clf= lr,x=x,y= y,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69da049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "\n",
      "Fold 2\n",
      "\n",
      "Fold 3\n",
      "\n",
      "Fold 4\n",
      "\n",
      "Fold 5\n",
      "\n",
      "Average Accuracy: 0.556\n",
      "\n",
      "Average Precision: 0.553\n",
      "\n",
      "Average Recall: 0.597\n",
      "\n",
      "Average F1-score: 0.573\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "k_fold_cross_validation_scores(clf= rf,x=x,y= y,k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
