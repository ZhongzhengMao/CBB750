{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAqFvZs6imq2"
      },
      "source": [
        "# Creating vector representations of seqs and SMILES\n",
        "*Siew Wei Feng*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim \n",
        "from gensim.models import Word2Vec \n",
        "import random \n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to obtain vector representations given protein sequences / SMILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def word2vec(dims,data,window_size,negative_size):\n",
        "    texts = [[word for word in re.findall(r'.{3}',document)] for document in list(data)]\n",
        "    #before\n",
        "    #model = Word2Vec(texts,size=dims,window=window_size,min_count=1,negative=negative_size,sg=1,sample=0.001,hs=1,workers=4)\n",
        "    #after\n",
        "    model = Word2Vec(texts,vector_size=dims,window=window_size,min_count=1,negative=negative_size,sg=1,sample=0.001,hs=1,workers=4)\n",
        "    #before\n",
        "    #vectors = pd.DataFrame([model[word] for word in (model.wv.vocab)])\n",
        "    #vectors['Word'] = list(model.wv.vocab)\n",
        "    #after\n",
        "    word_to_indexes = model.wv.key_to_index\n",
        "    indexes = [word_to_indexes[word] for word in word_to_indexes]\n",
        "    vectors = pd.DataFrame([model.wv.vectors[index] for index in indexes])\n",
        "    vectors['Word'] = [word for word in word_to_indexes]\n",
        "    word_vec = pd.DataFrame()\n",
        "    dictionary=[]\n",
        "    Index = []\n",
        "    for i in range(len(data)):\n",
        "        Index.append(i)\n",
        "    Index = list(Index)\n",
        "    # Word segmentation\n",
        "    for i in range(len(texts)):\n",
        "        i_word=[]         \n",
        "        for w in range(len(texts[i])):\n",
        "            i_word.append(Index[i])    \n",
        "        dictionary.extend(i_word)\n",
        "\n",
        "    word_vec['Id'] = dictionary\n",
        "\n",
        "    # word vectors generation\n",
        "    dictionary=[]\n",
        "    for i in range(len(texts)):\n",
        "        i_word=[]         \n",
        "        for w in range(len(texts[i])):\n",
        "            i_word.append(texts[i][w])    \n",
        "        dictionary.extend(i_word)\n",
        "    word_vec['Word'] = dictionary\n",
        "\n",
        "    del dictionary,i_word\n",
        "    word_vec = word_vec.merge(vectors,on='Word', how='left')\n",
        "    word_vec.columns = ['Id']+['Word']+[\"vec_{0}\".format(i) for i in range(0,dims)]\n",
        "\n",
        "    return word_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_embeddings(word_vec,dims):\n",
        "    word_vec=word_vec.drop('Word',axis=1)\n",
        "    name = [\"vec_{0}\".format(i) for i in range(0,dims)]\n",
        "    feature_embeddings = pd.DataFrame(word_vec.groupby(['Id'])[name].agg('mean')).reset_index()\n",
        "    feature_embeddings.columns=[\"Index\"]+[\"mean_ci_{0}\".format(i) for i in range(0,dims)]\n",
        "    return feature_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_pickle('pdb_train.p')\n",
        "test_df = pd.read_pickle('pdb_test.p')\n",
        "\n",
        "#uncomment to create dictionary where key= pdb_id and value = list of lig_ids belonging to ligands that bind to the protein\n",
        "\n",
        "#pdb_ids= list(train_df['pdb_id']) + list(test_df['pdb_id'])\n",
        "#lig_ids= list(train_df['lig_id']) + list(test_df['lig_id'])\n",
        "#unique_pdb_ids= np.unique(pdb_ids)\n",
        "#pdb_id_binds_to_lig_id= dict()\n",
        "\n",
        "#for pdb_id in unique_pdb_ids:\n",
        "    #indices = [i for i, x in enumerate(pdb_ids) if x == pdb_id]\n",
        "    #pdb_id_binds_to_lig_id[pdb_id]= np.take(lig_ids, indices)\n",
        "\n",
        "#f = open('pdb_id_binds_to_lig_id.pckl', 'wb')\n",
        "#pkl.dump(pdb_id_binds_to_lig_id, f)\n",
        "#f.close()\n",
        "\n",
        "train_df = train_df.sample(n=6000)\n",
        "test_df = test_df.sample(n=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open('pdb_id_binds_to_lig_id.pckl', 'rb')\n",
        "pdb_id_binds_to_lig_id = pkl.load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create negative samples (i.e. non-binding protein-ligand pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_negative_samples(df, negative_samples_per_positive_sample, pdb_id_binds_to_lig_id):\n",
        "    negative_samples = []\n",
        "    n_negative_samples = negative_samples_per_positive_sample*len(df)\n",
        "    while len(negative_samples) < n_negative_samples:\n",
        "        idx1, idx2 = np.random.choice(range(len(df)), 2, replace=False)\n",
        "        pdb_id = list(df['pdb_id'])[idx1]\n",
        "        lig_id = list(df['lig_id'])[idx2]\n",
        "        if lig_id not in pdb_id_binds_to_lig_id[pdb_id]:\n",
        "            negative_sample = df.iloc[idx1].copy()\n",
        "            negative_sample['ligand_xyz'] = df.iloc[idx2]['ligand_xyz']\n",
        "            negative_sample['ligand_xyz_2d'] = df.iloc[idx2]['ligand_xyz_2d']\n",
        "            negative_sample['ligand_bonds'] = df.iloc[idx2]['ligand_bonds']\n",
        "            negative_sample['smiles'] = df.iloc[idx2]['smiles']\n",
        "            negative_samples.append(negative_sample)\n",
        "    return pd.DataFrame(negative_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "negative_samples_per_positive_sample = 1\n",
        "n_positive_samples = len(train_df)\n",
        "n_negative_samples = negative_samples_per_positive_sample* n_positive_samples\n",
        "negative_samples = generate_negative_samples(train_df, negative_samples_per_positive_sample, pdb_id_binds_to_lig_id)\n",
        "train_df = pd.concat([train_df, negative_samples], ignore_index=True)\n",
        "y_train = pd.concat([pd.DataFrame.from_dict({'labels':[1 for i in range(n_positive_samples)]}),\n",
        "                     pd.DataFrame.from_dict({'labels':[0 for i in range(n_negative_samples)]})])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12000, 1)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "negative_samples_per_positive_sample = 1\n",
        "n_positive_samples = len(test_df)\n",
        "n_negative_samples = negative_samples_per_positive_sample * n_positive_samples\n",
        "negative_samples = generate_negative_samples(test_df, negative_samples_per_positive_sample, pdb_id_binds_to_lig_id)\n",
        "test_df = pd.concat([test_df, negative_samples], ignore_index=True)\n",
        "y_test = pd.concat([pd.DataFrame.from_dict({'labels':[1 for i in range(n_positive_samples)]}),\n",
        "                     pd.DataFrame.from_dict({'labels':[0 for i in range(n_negative_samples)]})])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4000, 1)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_positive_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_negative_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vectorize protein sequences in train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "seqs= list(train_df['seq']) + list(test_df['seq'])\n",
        "prot_vec=word2vec(dims= 100,data= seqs, window_size= 5,negative_size= 5) \n",
        "prot_feature_embeddings= feature_embeddings(word_vec= prot_vec,dims= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "seq_train= prot_feature_embeddings.iloc[0:len(train_df['seq']), 1:]\n",
        "seq_test= prot_feature_embeddings.iloc[len(train_df['seq']):, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vectorize ligand SMILES in train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "smiles= list(train_df['smiles']) + list(test_df['smiles'])\n",
        "smiles_vec=word2vec(dims= 100,data= smiles, window_size= 5,negative_size= 5) \n",
        "smiles_feature_embeddings= feature_embeddings(word_vec= smiles_vec,dims= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "smiles_train= smiles_feature_embeddings.iloc[0:len(train_df['smiles']), 1:]\n",
        "smiles_test= smiles_feature_embeddings.iloc[len(train_df['smiles']):, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create vector representation of protein-ligand pair by concatenating their vector representations together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = pd.concat([seq_train, smiles_train], ignore_index=True, axis=1)\n",
        "x_test = pd.concat([seq_test, smiles_test], ignore_index=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4000, 200)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save x_train, x_test, y_train and y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open('x_train.pckl', 'wb')\n",
        "pkl.dump(x_train, f)\n",
        "f.close()\n",
        "\n",
        "f = open('x_test.pckl', 'wb')\n",
        "pkl.dump(x_test, f)\n",
        "f.close()\n",
        "\n",
        "f = open('y_train.pckl', 'wb')\n",
        "pkl.dump(y_train, f)\n",
        "f.close()\n",
        "\n",
        "f = open('y_test.pckl', 'wb')\n",
        "pkl.dump(y_test, f)\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "#to reaccess\n",
        "f = open('x_train.pckl', 'rb')\n",
        "x_train = pkl.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('x_test.pckl', 'rb')\n",
        "x_test = pkl.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('y_train.pckl', 'rb')\n",
        "y_train = pkl.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('y_test.pckl', 'rb')\n",
        "y_test = pkl.load(f)\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
